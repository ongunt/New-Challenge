{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_NXU0lgz_vBK"
   },
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mt_h9B21AY5g",
    "outputId": "64bf3e6b-655d-4278-bd6d-136d54a149a5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E9d17uVBAbxS"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import os, time, warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l7NS0ShiDj71"
   },
   "outputs": [],
   "source": [
    "def resize_spectrogram(spec, length, fact=-80):\n",
    "\n",
    "    # Create an empty canvas to put spectrogram into\n",
    "    canvas = np.ones((len(spec), length)) * fact\n",
    "\n",
    "    if spec.shape[1] <= length:\n",
    "        canvas[:, : spec.shape[1]] = spec\n",
    "    else:\n",
    "        canvas[:, :length] = spec[:, :length]\n",
    "    return canvas\n",
    "\n",
    "def compute_mel_spec(filename, sr=8000, hop_length=512, duration=60.0):\n",
    "\n",
    "    # Loads the mp3 file\n",
    "    y, sr = librosa.load(filename, sr=sr)\n",
    "\n",
    "    # Compute the mel spectrogram\n",
    "    x_mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "    # Apply logarithmic dB-scale to spectrogram and set maximum to 0 dB\n",
    "    x_mel = librosa.power_to_db(x_mel, ref=np.max)\n",
    "\n",
    "    # Compute mean strength per frequency for mel spectrogram\n",
    "    mel_strength = np.mean(x_mel, axis=1)\n",
    "\n",
    "    # Estimate the desired length of the spectrogram\n",
    "    length = int(duration * sr / hop_length)\n",
    "\n",
    "    # print(np.min(x_mel))\n",
    "    # print(np.max(x_mel))\n",
    "\n",
    "    # Put mel spectrogram into the right shape\n",
    "    x_mel = resize_spectrogram(x_mel, length)\n",
    "\n",
    "    x_mel = librosa.util.normalize(x_mel, axis=1)\n",
    "    x_mel = np.ones(x_mel.shape) + x_mel\n",
    "\n",
    "\n",
    "    return x_mel, mel_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "siJg1ZgLGXDl"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4Fe_e7jeDGgL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3Vz8DHqqYs_",
    "outputId": "a2bee7b3-0b1a-4269-ba49-50e375c0ab08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PAyxkEa8DKfY"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6nUrqctkSk3I"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lFeteD6XRaiH"
   },
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, audio_file_list, scores):\n",
    "        self.audio_file_list = audio_file_list\n",
    "        self.scores = scores\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.audio_file_list[index]\n",
    "        # img, _ = librosa.load(img, sr=16000)\n",
    "        # print(type(img))\n",
    "        # img = torch.tensor(img, dtype=torch.float32)\n",
    "        # img = torch.mean(img, dim=0).unsqueeze(0)\n",
    "        # img = torchaudio.transforms.Spectrogram()(img)\n",
    "        \n",
    "        \n",
    "        img, _ = compute_mel_spec(f'/home/ongun/sustained-phonation-features-master/vowel/{img}')\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        # print(img.shape)\n",
    "        # img = torch.mean(img, dim=0).unsqueeze(0)\n",
    "        # img = F.pad(img, (0, 1000 - img.shape[1]))\n",
    "        img = img.reshape([1, img.shape[0], img.shape[1]])\n",
    "        # img = generate_features(img)\n",
    "        # torch.index_select(img, 1, torch.LongTensor([2,0,1]))\n",
    "        # print(img.shape)\n",
    "        \n",
    "        def ordinal_labeler(score):\n",
    "            levels = [1]*score + [0]*(39 - score)\n",
    "            levels = torch.tensor(levels, dtype=torch.float32)\n",
    "            return levels\n",
    "        \n",
    "        score = self.scores[index]\n",
    "        label = np.array(ordinal_labeler(score))\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        count = len(self.audio_file_list)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTGkLQ9OnHPT",
    "outputId": "075560f3-a728-4dbb-d56c-6cdf60e29af0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ME-fbJQnQZz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTQVESn0oQ_P",
    "outputId": "a1a2d428-29f1-4170-dd72-ccdd7ca00a0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSIWV3CjoUIT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"modified_data.csv\")\n",
    "df1 = df.iloc[::2]\n",
    "# remove even rows:\n",
    "df2 = df.iloc[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>excercise_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1614</td>\n",
       "      <td>20220130013629.wav</td>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>11</td>\n",
       "      <td>evening_task:answer_question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1614</td>\n",
       "      <td>20220131204837.wav</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>12</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1614</td>\n",
       "      <td>20220201232615.wav</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>8</td>\n",
       "      <td>evening_task:answer_question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1614</td>\n",
       "      <td>20220203191000.wav</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>12</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1614</td>\n",
       "      <td>20220205194422.wav</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>14</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1717</td>\n",
       "      <td>20220420222748.wav</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>17</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1717</td>\n",
       "      <td>20220421230009.wav</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>18</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1717</td>\n",
       "      <td>20220423230218.wav</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>20</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1717</td>\n",
       "      <td>20220424233122.wav</td>\n",
       "      <td>2022-04-24</td>\n",
       "      <td>20</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1717</td>\n",
       "      <td>20220425230238.wav</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>18</td>\n",
       "      <td>evening_task:read_text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid            filename        date  score  \\\n",
       "1      1614  20220130013629.wav  2022-01-30     11   \n",
       "3      1614  20220131204837.wav  2022-01-31     12   \n",
       "5      1614  20220201232615.wav  2022-02-01      8   \n",
       "7      1614  20220203191000.wav  2022-02-03     12   \n",
       "9      1614  20220205194422.wav  2022-02-05     14   \n",
       "..      ...                 ...         ...    ...   \n",
       "305    1717  20220420222748.wav  2022-04-20     17   \n",
       "307    1717  20220421230009.wav  2022-04-21     18   \n",
       "309    1717  20220423230218.wav  2022-04-23     20   \n",
       "311    1717  20220424233122.wav  2022-04-24     20   \n",
       "313    1717  20220425230238.wav  2022-04-25     18   \n",
       "\n",
       "                   excercise_type  \n",
       "1    evening_task:answer_question  \n",
       "3          evening_task:read_text  \n",
       "5    evening_task:answer_question  \n",
       "7          evening_task:read_text  \n",
       "9          evening_task:read_text  \n",
       "..                            ...  \n",
       "305        evening_task:read_text  \n",
       "307        evening_task:read_text  \n",
       "309        evening_task:read_text  \n",
       "311        evening_task:read_text  \n",
       "313        evening_task:read_text  \n",
       "\n",
       "[157 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "djy49TrcRktr"
   },
   "outputs": [],
   "source": [
    "audio_list = np.array(df1['filename'].tolist())\n",
    "score_list = np.array(df1['score'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "i0hHwBmfT7zt"
   },
   "outputs": [],
   "source": [
    "indices = np.arange(len(audio_list))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "limit = int(len(indices)*0.7)\n",
    "\n",
    "X_train, X_test = audio_list[indices[:limit]], audio_list[indices[limit:]]\n",
    "y_train, y_test = score_list[indices[:limit]], score_list[indices[limit:]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "l0YxzEPnWj9P"
   },
   "outputs": [],
   "source": [
    "train_data = MyCustomDataset(X_train, y_train)\n",
    "test_data = MyCustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kCMWes5zW1vd"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "num_classes = 40\n",
    "batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Q-Aq048QW-xe"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4eMmfg48XBXH"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BQmeMIP-BzPY"
   },
   "outputs": [],
   "source": [
    "def prediction2label(pred: np.ndarray):\n",
    "    \"\"\"Convert ordinal predictions to class labels, e.g.\n",
    "    \n",
    "    [0.9, 0.1, 0.1, 0.1] -> 0\n",
    "    [0.9, 0.9, 0.1, 0.1] -> 1\n",
    "    [0.9, 0.9, 0.9, 0.1] -> 2\n",
    "    etc.\n",
    "    \"\"\"\n",
    "    return (pred > 0.5).cumprod(axis=1).sum(axis=1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7CyvAEpOXfuc"
   },
   "outputs": [],
   "source": [
    "importance_weights = torch.ones(39, dtype=torch.float).to(device)\n",
    "\n",
    "def loss_fn2(logits, levels, imp=importance_weights):\n",
    "    val = (-torch.sum((F.logsigmoid(logits)*levels\n",
    "                      + (F.logsigmoid(logits) - logits)*(1-levels))*imp,\n",
    "           dim=1))\n",
    "    return torch.mean(val)\n",
    "\n",
    "def loss_fn(logits, levels):\n",
    "    logits = prediction2label(logits)\n",
    "    modified_target = torch.zeros_like(logits)\n",
    "\n",
    "    # Fill in ordinal target function, i.e. 0 -> [1,0,0,...]\n",
    "    for i, target in enumerate(levels):\n",
    "        modified_target[i, 0:target+1] = 1\n",
    "\n",
    "    return nn.MSELoss(reduction='none')(logits, modified_target).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CzqMGmfNXJd5"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=7, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(111360*2, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 512)\n",
    "        self.fc3 = nn.Linear(512, 39)\n",
    "        # self.last = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape([out.size(0), -1])\n",
    "        # print(out.shape)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        # out = self.last(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "# Loss and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQO12XbHjGND",
    "outputId": "00b2e28e-200f-486c-a25b-7c967ffcd830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=222720, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "G6vksAstv8sw"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1yBFUZpXONE",
    "outputId": "cfdde45c-0b24-42d3-d9bc-45401598fd19"
   },
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Run the forward pass\n",
    "        images = images\n",
    "        labels = labels\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn2(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # correct = (predicted == labels).sum().item()\n",
    "        # acc_list.append(correct / total)\n",
    "    print(f'epoch: {epoch}: acc:','loss: ',np.mean(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_h8KFrSq5CyY"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model_scripted_7.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ConvNet()\n",
    "#model.load_state_dict(torch.load(file))\n",
    "model.load_state_dict(torch.load('model_scripted_7.pt',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(test_loader: DataLoader, model: nn.Module):\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    device=\"cuda\"\n",
    "    acc_list=[]\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "           \n",
    "            predictions = model(data)\n",
    "            \n",
    "            total = labels.size(0)\n",
    "            predicted = prediction2label(predictions, 0.5)\n",
    "            targets = prediction2label(labels, 0.5)\n",
    "            num_correct = (predicted == targets).sum().item()\n",
    "            acc_list.append(num_correct/total)\n",
    "        print(f\"Test Accuracy of the model: {np.mean(acc_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
